<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Introduction to the `apm` Package • apm</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to the `apm` Package">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">apm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/apm.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/tl2624/apm/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Introduction to the `apm` Package</h1>
                        <h4 data-toc-skip class="author"></h4>
            
            <h4 data-toc-skip class="date">2025-03-05</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/tl2624/apm/blob/main/vignettes/apm.Rmd" class="external-link"><code>vignettes/apm.Rmd</code></a></small>
      <div class="d-none name"><code>apm.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The <code>apm</code> package implements <em>Averaged Prediction
Models (APM)</em>, a Bayesian model averaging approach for controlled
pre-post designs. These designs compare differences over time between a
group that becomes exposed (treated group) and one that remains
unexposed (comparison group). With appropriate causal assumptions, they
can identify the causal effect of the exposure/treatment.</p>
<p>In APM, we specify a collection of models that predict untreated
outcomes. Our causal identifying assumption is that the model’s
prediction errors would be equal (in expectation) in the treated and
comparison groups in the absence of the exposure. This is a
generalization of familiar methods like Difference-in-Differences (DiD)
and Comparative Interrupted Time Series (CITS).</p>
<p>Because many models may be plausible for this prediction task, we
combine them using Bayesian model averaging. We weight each model by its
robustness to violations of the causal assumption.</p>
</div>
<div class="section level2">
<h2 id="methodology-overview">Methodology Overview<a class="anchor" aria-label="anchor" href="#methodology-overview"></a>
</h2>
<p>Our identification framework begins with prediction and correction
steps. First, we train a model on pre-intervention data to predict
untreated outcomes in the post-intervention period. Then, we correct the
treated group’s predictions using the comparison group’s
post-intervention prediction errors, which adjusts for shared
time-varying shocks. The identifying assumption is that, without the
policy change, prediction errors would be equal (in expectation) across
treated and comparison groups.</p>
<p>We specify a collection of plausible models for this prediction task
and compare across them using robustness to the causal assumption.
Specifically, we quantify each model’s differential prediction errors
(i.e., differences between the treated and untreated group’s prediction
errors) during a series of pre-intervention validation periods. Taking
the max as a summary across these periods, we consider models with
smaller maximum differential prediction errors more robust.</p>
<p>Then we apply Bayesian model averaging (BMA), weighting each model by
its posterior probability of being the most robust. Taking an “informal
Bayesian approach”, we sample model parameters from a quasi-posterior
<span class="citation">(<a href="#ref-gelmanhill2006">Gelman and Hill
2006, 140</a>)</span>. This is a multivariate Normal distribution with
mean equal to the estimated parameters of the fitted models and a
variance-covariance matrix that incorporates across-model correlations.
For each parameter draw, we compute the models’ differential prediction
errors and take the max over the validation periods. Each model’s weight
is the proportion of draws in which it minimizes the maximum
differential prediction error (i.e., is most robust). Finally, using the
corrected predictions from our averaged model, we estimate the average
treatment effect on the treated (ATT).</p>
<div class="float">
<img src="apm_summary%2Fapm_summary.svg" style="width:100.0%" alt="Summary of the APM method"><div class="figcaption">Summary of the APM method</div>
</div>
<p>For inference, we apply a fractional weighted bootstrap <span class="citation">(<a href="#ref-xuetal2020">Xu et al. 2020</a>)</span>.
It takes into account uncertainty about the models’ performance, but not
the uncertainty in the BMA weights themselves, which would be
computationally infeasible. Following <span class="citation">Antonelli,
Papadogeorgou, and Dominici (<a href="#ref-antonellietal2022">2022</a>)</span>, we estimate overall
variance as the sum of two components: (1) sampling variance with fixed
model uncertainty and (2) model uncertainty variance with fixed sampling
uncertainty.</p>
<p>Finally, we can also perform causal sensitivity analyses by scaling
the models’ maximum differential prediction error in the validation
periods by a factor
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>.
This enables sensitivity measures such as:</p>
<ul>
<li>constructing sensitivity bounds for a particular
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
as in <span class="citation">Manski and Pepper (<a href="#ref-manskipepper2018">2018</a>)</span> and <span class="citation">Rambachan and Roth (<a href="#ref-rambachanroth2023">2023</a>)</span>
</li>
<li>finding the value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
that would reverse the sign of the causal effect</li>
<li>finding the value of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>M</mi><annotation encoding="application/x-tex">M</annotation></semantics></math>
that would lead the confidence interval to include 0</li>
</ul>
<p>The package implements the APM methods via three key functions:</p>
<ul>
<li><p><code><a href="../reference/apm_mod.html">apm_mod()</a></code> constructs candidate models that can
predict untreated outcomes in both treated and comparison
groups.</p></li>
<li><p><code><a href="../reference/apm_pre.html">apm_pre()</a></code> fits these candidate models to
pre-treatment validation data and generates the BMA weights for each
model.</p></li>
<li><p><code><a href="../reference/apm_est.html">apm_est()</a></code> estimates the ATT, given the BMA weights,
and constructs both statistical and causal bounds around it.</p></li>
</ul>
</div>
<div class="section level2">
<h2 id="example-estimating-the-effect-of-missouris-gun-policy-change">Example: Estimating the Effect of Missouri’s Gun Policy Change<a class="anchor" aria-label="anchor" href="#example-estimating-the-effect-of-missouris-gun-policy-change"></a>
</h2>
<p>In this example, we apply APM to estimate the effect of Missouri’s
2007 repeal of its permit-to-purchase law on gun homicide rates <span class="citation">(<a href="#ref-websteretal2014">Webster, Crifasi, and
Vernick 2014</a>; <a href="#ref-hasegawaetal2019">Hasegawa, Webster, and
Small 2019</a>)</span>.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/tl2624/apm" class="external-link">apm</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="load-example-data">Load Example Data<a class="anchor" aria-label="anchor" href="#load-example-data"></a>
</h3>
<p>The package provides an example dataset with pre- and post-policy
homicide rates:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="st">"ptpdata"</span>, package <span class="op">=</span> <span class="st">"apm"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Inspect the dataset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">ptpdata</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##      state year deaths crude_rate age_adj_rate group treat</span></span>
<span><span class="co">## 1 Arkansas 1994    205        8.2          8.2     0     0</span></span>
<span><span class="co">## 2 Arkansas 1995    212        8.4          8.4     0     0</span></span>
<span><span class="co">## 3 Arkansas 1996    164        6.4          6.4     0     0</span></span>
<span><span class="co">## 4 Arkansas 1997    196        7.5          7.6     0     0</span></span>
<span><span class="co">## 5 Arkansas 1998    155        5.9          6.0     0     0</span></span>
<span><span class="co">## 6 Arkansas 1999    118        4.4          4.5     0     0</span></span></code></pre>
<p>The dataset includes:</p>
<ul>
<li><p><code>state</code>: State name</p></li>
<li><p><code>year</code>: Year of observation</p></li>
<li><p><code>deaths</code>: The number of gun homicide deaths</p></li>
<li><p><code>crude_rate</code>: Gun homicide rate per 100,000</p></li>
<li><p><code>age_adj_rate</code>: Gun homicide rate per 100,000 adjusted
for age</p></li>
<li><p><code>group</code>: Indicator for Missouri (1 = Missouri, 0 =
comparison group)</p></li>
<li><p><code>treat</code>: Indicator for Missouri in post-treatment year
(2008+) (1 = treated, 0 = untreated)</p></li>
</ul>
<p>Note that observations with <code>year == 2008</code> are the average
of a state’s observations over all post-treatment periods (2008 -
2016).</p>
</div>
<div class="section level3">
<h3 id="define-candidate-models">Define Candidate Models<a class="anchor" aria-label="anchor" href="#define-candidate-models"></a>
</h3>
<p>APM supports a range of model options:</p>
<ul>
<li><p><code>formula_list</code>: list of model formulas with outcome on
left-hand side and predictors on right-hand side, e.g.,
<code>formula_list = crude_rate ~ 1</code>.</p></li>
<li><p><code>family</code>: list of family specifications passed to
<code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">stats::glm()</a></code> when fitting models in <code><a href="../reference/apm_pre.html">apm_pre()</a></code>;
<code>"negbin"</code> can also be supplied to request negative binomial
model with log link fit using <code><a href="https://rdrr.io/pkg/MASS/man/glm.nb.html" class="external-link">MASS::glm.nb()</a></code>. To see list
of family specifications, run <code><a href="https://rdrr.io/r/stats/family.html" class="external-link">?family</a></code>.</p></li>
<li><p><code>lag</code>: vector of integers outcome lags to be used as
predictors. For example, <code>lag = 3</code> means to include lag-1,
lag-2, and lag-3 outcomes as predictors. Default is 0 (for no
lags).</p></li>
<li><p><code>diff_k</code>: vector of integers indicating outcome lags
to be used as offsets. For example, <code>diff_k = 1</code> means prior
time point’s outcome will be included as offset, equivalent to using the
outcome minus its corresponding lag as the model’s outcome. Default is 0
for no lags. Any models with a <code>diff_k</code> value less than a
<code>lag</code> value are removed automatically. When used with a
family with log link, lags are automatically log-transformed;
<code><a href="../reference/apm_pre.html">apm_pre()</a></code> will return an error if non-positive values are
present in the outcome.</p></li>
<li><p><code>log</code>: logical vector indicating whether outcome
should be log-transformed. Default is <code>FALSE</code> to use the
original outcome. When <code>lag</code> or <code>diff_k</code> are
greater than 0, outcome lags will also be log-transformed if
<code>TRUE</code>. When family has log link and <code>diff_k</code> is
greater than 0, lag in offset will be log transformed.</p></li>
<li><p><code>time_trend</code>: vector of integers indicating powers to
be included in a time trend. For example, <code>time_trend = 2</code>
means to include as predictors time variable and its square. A value of
0 (the default) means continuous time is not included as
predictor.</p></li>
<li><p><code>fixef</code>: logical vector indicating whether to include
unit fixed effects as predictors. Default is
<code>FALSE</code>.</p></li>
</ul>
<p>These lists of model options are combined factorially to create a
collection of candidate models.</p>
<p>In this example, we specify two options for lags (no lag and lag-1),
two options for outcome differences (no offset and immediate prior
outcome), two options for the outcome scale (original and log
transformed), and two options for time trends (no time trend and linear
time trend), to get a set of candidate models:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">models</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/apm_mod.html">apm_mod</a></span><span class="op">(</span>formula_list <span class="op">=</span> <span class="va">crude_rate</span> <span class="op">~</span> <span class="fl">1</span>,</span>
<span>                  family <span class="op">=</span> <span class="st">"gaussian"</span>,</span>
<span>                  lag <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span>,</span>
<span>                  diff_k <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span>,</span>
<span>                  log <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>                  time_trend <span class="op">=</span> <span class="fl">0</span><span class="op">:</span><span class="fl">1</span>,</span>
<span>                  fixef <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>This produces 12 candidate models, all of which use the
<code>"gaussian"</code> family (with an identity link function). This is
fewer than the full factorial combination because of the embedded logic
for combining outcome differences and lags (see above).</p>
</div>
<div class="section level3">
<h3 id="fit-candidate-models-to-pre-treatment-data">Fit Candidate Models to Pre-Treatment Data<a class="anchor" aria-label="anchor" href="#fit-candidate-models-to-pre-treatment-data"></a>
</h3>
<p>We now fit all 12 models to pre-treatment data. For each model and
each pre-treatment validation period, we compute the observed difference
in average prediction errors between treated and comparison groups. From
these differences in average prediction errors, we compute the Bayesian
model averaging (BMA) weights that are eventually passed to
<code><a href="../reference/apm_est.html">apm_est()</a></code> for estimation of the average effect of treatment
on the treated (the ATT).</p>
<p>The function <code><a href="../reference/apm_pre.html">apm_pre()</a></code> does the model fitting. It
requires a data frame that contains a group indicator variable and a
time variable. We specify <code>1999:2007</code> as the validation years
in which each model will be. Each validation year’s fit will be based on
all data prior to that year. Therefore, we set the first validation
period to 1999 so that even in the first validation year, we can train
the models on five years of data (i.e., <code>1994:1998</code>). We
specify the number of quasi-posterior draws using the
<code>nsim = 1000</code> argument; more draws gives a better
approximation to the model posterior, but can slow down the
computation.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Set seed for reproducibility: ensures random sampling from </span></span>
<span><span class="co"># multivariate Normal produces same results each time code is run</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">098556947</span><span class="op">)</span></span>
<span><span class="va">fits</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/apm_pre.html">apm_pre</a></span><span class="op">(</span>models <span class="op">=</span> <span class="va">models</span>,</span>
<span>                data <span class="op">=</span> <span class="va">ptpdata</span>,</span>
<span>                group_var <span class="op">=</span> <span class="st">"group"</span>,</span>
<span>                time_var <span class="op">=</span> <span class="st">"year"</span>,</span>
<span>                unit_var <span class="op">=</span> <span class="st">"state"</span>,</span>
<span>                val_times <span class="op">=</span> <span class="fl">1999</span><span class="op">:</span><span class="fl">2007</span>,</span>
<span>                nsim <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span></code></pre></div>
<p>We can view the largest average differential prediction error for
each model and the BMA weights given to each model using
<code><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary()</a></code> on the returned object:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">fits</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##                                   BMA weights Max|errors|  </span></span>
<span><span class="co">## FE                                      0.000       0.850  </span></span>
<span><span class="co">## AR(1) + FE                              0.022       0.630  </span></span>
<span><span class="co">## FE (1st diff)                           0.000       0.997  </span></span>
<span><span class="co">## FE (log)                                0.000       0.826  </span></span>
<span><span class="co">## AR(1) + FE (log)                        0.977       0.584 *</span></span>
<span><span class="co">## FE (log, 1st diff)                      0.000       0.874  </span></span>
<span><span class="co">## linear trend + FE                       0.000       1.102  </span></span>
<span><span class="co">## linear trend + AR(1) + FE               0.001       0.719  </span></span>
<span><span class="co">## linear trend + FE (1st diff)            0.000       1.264  </span></span>
<span><span class="co">## linear trend + FE (log)                 0.000       0.988  </span></span>
<span><span class="co">## linear trend + AR(1) + FE (log)         0.000       0.933  </span></span>
<span><span class="co">## linear trend + FE (log, 1st diff)       0.000       1.207  </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Use `plot()` to plot prediction errors and BMA weights.</span></span></code></pre>
<p>We can plot the simulation-based posterior distribution of which
model is most robust. The probabilities are the proportions of
simulations in which each model is the winner.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fits</span>, type <span class="op">=</span> <span class="st">"weights"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<img src="apm_files/figure-html/fig.model_weights-1.png" alt="Bayesian Model Averaging (BMA) Weights for Model Selection." width="\textwidth"><p class="caption">
Bayesian Model Averaging (BMA) Weights for Model Selection.
</p>
</div>
<p>We can see the differential prediction errors in each model and year.
Here, the winning model is highlighted: it is the model that includes a
lag-1 outcome as a predictor and log-transforms the outcome. The maximum
differential prediction error was observed in 2005.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fits</span>, type <span class="op">=</span> <span class="st">"errors"</span><span class="op">)</span></span></code></pre></div>
<p><img src="apm_files/figure-html/unnamed-chunk-6-1.png" width="\textwidth" style="display: block; margin: auto;"></p>
<p>The plot below shows the predictions from this model in each
validation period. The observed outcomes are displayed as points and the
predicted outcomes as lines.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fits</span>, type <span class="op">=</span> <span class="st">"predict"</span><span class="op">)</span></span></code></pre></div>
<p><img src="apm_files/figure-html/unnamed-chunk-7-1.png" width="\textwidth" style="display: block; margin: auto;"></p>
<p>Finally, we can also show the winning model’s corrected predictions,
that is, after incorporating the prediction error in the control group
<!-- this seems like an overly complicated definition; the y axis scale says "outcome" rather than error; could it be that in both this plot and the one above, it's not on the prediction error scale, but the scale of the predictions themselves? I think that's true, the figure titles are wrong, they're showing predictions, not errors -->
To observe the corrected predictions, we can set
<code>type = "corrected"</code>, which is the prediction for the treated
group, corrected for the comparison group’s prediction error.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fits</span>, type <span class="op">=</span> <span class="st">"corrected"</span><span class="op">)</span></span></code></pre></div>
<p><img src="apm_files/figure-html/unnamed-chunk-8-1.png" width="\textwidth" style="display: block; margin: auto;"></p>
</div>
<div class="section level3">
<h3 id="estimation-and-inference">Estimation and Inference<a class="anchor" aria-label="anchor" href="#estimation-and-inference"></a>
</h3>
<p>To estimate the ATT and conduct inference, we feed the output of a
call to <code><a href="../reference/apm_pre.html">apm_pre()</a></code> into <code><a href="../reference/apm_est.html">apm_est()</a></code>. The
<code>M</code> argument is the sensitivity parameter for set
identification, which by default is set to <code>M = 0</code>. When
<code>M</code> is set to a value greater than 0, <code><a href="../reference/apm_est.html">apm_est()</a></code>
will return estimates of the lower and upper bounds of the ATT. These
bounds can incorporate both the uncertainty due to possible causal
violations and sampling uncertainty. The <code>R</code> argument is the
number of bootstrap iterations used to estimate the sampling variance,
holding model uncertainty fixed.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">est</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/apm_est.html">apm_est</a></span><span class="op">(</span>fits <span class="op">=</span> <span class="va">fits</span>,</span>
<span>               post_time <span class="op">=</span> <span class="fl">2008</span>,</span>
<span>               M <span class="op">=</span> <span class="fl">1</span>,</span>
<span>               R <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>               all_models <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<p>To examine the estimates and uncertainty bounds, we run the
following. The <code>level = 0.95</code> argument specifies the
statistical confidence level; to ignore sampling uncertainty, set
<code>level = 0</code>.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">est</span>, level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       Estimate Std. Error CI low CI high z_value Pr(&gt;|z|)    </span></span>
<span><span class="co">## ATT     1.1414     0.1226 0.9011  1.3817    9.31   &lt;2e-16 ***</span></span>
<span><span class="co">## M = 1        .          . 0.1367  2.0099       .        .    </span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre>
<p>The standard error is the square root of the sum of two variances:
(1) the estimated sampling variance holding model uncertainty fixed and
(2) estimated model uncertainty variance holding the sampling
uncertainty fixed. For the <code>ATT</code> row, the <code>CI low</code>
and <code>CI high</code> outputs are the lower and upper confidence
bounds for the ATT. The <code>CI low</code> output for the
<code>M = 1</code> row is the lower confidence bound of the ATT’s lower
sensitivity bound. The <code>CI high</code> output for the
<code>M = 1</code> row is the upper confidence bound of the ATT’s upper
sensitivity bound.</p>
<p>The figure below shows the estimated ATT under each model plotted
against the maximum absolute difference in average prediction errors for
that model. The model with the smallest maximum absolute difference in
average prediction errors is displayed in red. The size of the points
correspond to the BMA weights.</p>
<p>Small variation in the ATT estimates (y axis) across values of
maximum absolute differences in prediction errors (x axis) suggests that
we do not face a stark trade-off between model plausibility and
robustness.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">est</span><span class="op">)</span></span></code></pre></div>
<p><img src="apm_files/figure-html/unnamed-chunk-11-1.png" width="\textwidth" style="display: block; margin: auto;"></p>
</div>
<div class="section level3">
<h3 id="sensitivity-analysis">Sensitivity Analysis<a class="anchor" aria-label="anchor" href="#sensitivity-analysis"></a>
</h3>
<p>We can also apply a sensitivity analysis to increasing values of
<code>M</code>. For example, below we estimate the ATT’s bounds under
values of <code>M</code> from 1 to 2 in increments of 0.25.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">est</span>, M <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span>from <span class="op">=</span> <span class="fl">1</span>, to <span class="op">=</span> <span class="fl">2</span>, by <span class="op">=</span> <span class="fl">0.25</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##          Estimate Std. Error  CI low CI high z_value Pr(&gt;|z|)    </span></span>
<span><span class="co">## ATT        1.1414     0.1226  0.9011  1.3817    9.31   &lt;2e-16 ***</span></span>
<span><span class="co">## M = 1           .          .  0.1367  2.0099       .        .    </span></span>
<span><span class="co">## M = 1.25        .          . -0.0672  2.2014       .        .    </span></span>
<span><span class="co">## M = 1.5         .          . -0.2730  2.3991       .        .    </span></span>
<span><span class="co">## M = 1.75        .          . -0.4803  2.6009       .        .    </span></span>
<span><span class="co">## M = 2           .          . -0.6886  2.8054       .        .    </span></span>
<span><span class="co">## ---</span></span>
<span><span class="co">## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre>
<p>This output shows that our 95% confidence interval for the ATT’s
lower bound excludes 0 when <code>M = 1.25</code>, but not when
<code>M = 1.5</code>. To find the exact changepoint value of
<code>M</code>, we can run the following.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/robustness_bound.html">robustness_bound</a></span><span class="op">(</span><span class="va">est</span>, level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1.167954</span></span></code></pre>
<p>We can also run <code><a href="../reference/robustness_bound.html">robustness_bound()</a></code> when the level is
<code>level = 0</code>, which will give us the value of <code>M</code>
in which the sensitivity bound (not statistical confidence bounds) begin
to bracket 0.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/robustness_bound.html">robustness_bound</a></span><span class="op">(</span><span class="va">est</span>, level <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 1.950976</span></span></code></pre>
<p>As we would expect, the changepoint value of <code>M</code> is
greater when <code>level = 0</code>.</p>
</div>
</div>
<div class="section level2">
<h2 id="interpretation-of-results">Interpretation of Results<a class="anchor" aria-label="anchor" href="#interpretation-of-results"></a>
</h2>
<p>The BMA point estimate (<code>M = 0</code>) is 1.14, with a standard
error of 0.12, yielding a 95% confidence interval of [0.9, 1.38]. This
suggests that Missouri’s repeal of its permit-to-purchase law increased
the state’s gun homicide rate by 0.9 to 1.38 per 100,000 people. Given
Missouri’s 2007 homicide rate of 4.5 per 100,000 people, the estimated
increase of 1.14 represents a 25% rise. The changepoint value of M for
the BMA estimator is 1.95. That is, if differential prediction errors
were nearly twice what were seen in the validation periods, the point
estimate would no longer indicate an increase in the gun homicide rate.
Additionally, the lower bound estimator’s 95% confidence interval
includes zero when M reaches 1.17. That is, at this multiplier of the
differential prediction errors seen in the validation period, our
statistical uncertainty bounds around the effect estimate would begin to
include 0.</p>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>The <code>apm</code> R package implements Averaged Prediction Models
(APM), a unified framework for causal inference in controlled pre-post
settings. APM generalizes a broad class of prediction-based methods by
combining outcome prediction with error correction using a comparison
group. The package also incorporates Bayesian Model Averaging to select
the most robust model based on pre-period data.</p>
<p>Through an application to Missouri’s 2007 permit-to-purchase law
repeal, our results suggest that a lagged dependent variable model with
unit fixed effects on the log scale was the most robust choice, leading
to an estimated increase of 1.14 homicides per 100,000 people.
Sensitivity analysis indicates that for the estimated effect to be
indistinguishable from zero, assumption violations would need to exceed
1.95 times the worst pre-period discrepancies, compared to as low as
0.79 under single-model approaches.</p>
<p>Built on a unified identification framework, APM offers a flexible,
data-driven approach to causal inference in controlled pre-post
settings. The <code>apm</code> package prioritizes model averaging and
robustness over assuming a single “correct” model while efficiently
accounting for both sampling and model uncertainty. This ensures that
researchers can achieve greater flexibility in model selection while
maintaining rigorous and principled inference.</p>
<p>For more details, see:</p>
<ul>
<li><p><a href="https://github.com/ngreifer/apm" class="external-link">GitHub
Repository</a></p></li>
<li><p><a href="https://static1.squarespace.com/static/5d54a19a5a1edf0001ea677a/t/67925707ef4f220a4827ce23/1737643784263/apm_preprint.pdf" class="external-link">Paper
on APM Methodology</a></p></li>
</ul>
<hr>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-antonellietal2022" class="csl-entry">
Antonelli, Joseph, Georgia Papadogeorgou, and Francesca Dominici. 2022.
<span>“Causal Inference in High Dimensions: A Marriage Between
<span>B</span>ayesian Modeling and Good Frequentist Properties.”</span>
<em>Biometrics</em> 78 (1): 100–114.
</div>
<div id="ref-gelmanhill2006" class="csl-entry">
Gelman, Andrew, and Jennifer Hill. 2006. <em>Data Analysis Using
Regression and Multilevel/Hierarchical Models</em>. New York, NY:
Cambridge University Press.
</div>
<div id="ref-hasegawaetal2019" class="csl-entry">
Hasegawa, Raiden B, Daniel W Webster, and Dylan S Small. 2019.
<span>“Evaluating <span>M</span>issouri’s Handgun Purchaser Law: A
Bracketing Method for Addressing Concerns about History Interacting with
Group.”</span> <em>Epidemiology</em> 30 (3): 371–79.
</div>
<div id="ref-manskipepper2018" class="csl-entry">
Manski, Charles F, and John V Pepper. 2018. <span>“How Do Right-to-Carry
Laws Affect Crime Rates? <span>C</span>oping with Ambiguity Using
Bounded-Variation Assumptions.”</span> <em>The Review of Economics and
Statistics</em> 100 (2): 232–44.
</div>
<div id="ref-rambachanroth2023" class="csl-entry">
Rambachan, Ashesh, and Jonathan Roth. 2023. <span>“A More Credible
Approach to Parallel Trends.”</span> <em>Review of Economic Studies</em>
90 (5): 2555–91.
</div>
<div id="ref-websteretal2014" class="csl-entry">
Webster, Daniel, Cassandra Kercher Crifasi, and Jon S Vernick. 2014.
<span>“Effects of the Repeal of <span>M</span>issouri’s Handgun
Purchaser Licensing Law on Homicides.”</span> <em>Journal of Urban
Health: Bulletin of the <span>N</span>ew <span>Y</span>ork
<span>A</span>cademy of <span>M</span>edicine</em> 91 (2): 293–302.
</div>
<div id="ref-xuetal2020" class="csl-entry">
Xu, Li, Chris Gotwalt, Yili Hong, Caleb B King, and William Q Meeker.
2020. <span>“Applications of the Fractional-Random-Weight
Bootstrap.”</span> <em>The American Statistician</em> 74 (4): 345–58.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Thomas Leavitt, Laura Hatfield, Noah Greifer.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
